# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FseMJ4NO870nF4LRe35HConnd4AkJuM-
"""

import spacy
import numpy as np
import pandas as pd
import seaborn as sns

dfComment = pd.read_csv("/content/train.csv")

dfComment.head()

dfComment.drop(['severe_toxic', 'threat'] ,axis=1,inplace = True)
dfComment



dfComment['emotion'] = dfComment[['toxic','obscene','insult','identity_hate']].astype(str).apply(lambda x: ''.join(x), axis=1)

def valToDecimal(x):
    return int(x,2)

dfComment['emotion'] = dfComment['emotion'].apply(valToDecimal)

dfComment[dfComment['toxic']==1]

dfComment.drop(['id','toxic', 'obscene','insult','identity_hate'],axis=1,inplace = True)
''' dfComment['emotion'] = dfComment['emotion'].apply(lambda x: 1 if x != 0 else x) '''

dfComment[dfComment['emotion']==0]

dfComment['emotion'].value_counts()

newDf = dfComment.drop(dfComment[dfComment['emotion'] == 0][:130000].index)
newDf['emotion'].value_counts()

nlp = spacy.load('en_core_web_sm')

def treat_comment(comment):
    spacy_comment = nlp(comment, disable=["parser", "tagger", "ner", "textcat"])
    treated_tokens = [w.text for w in spacy_comment if w.is_alpha and not w.is_stop]
    return " ".join(treated_tokens)

newDf['comment_text'] = newDf['comment_text'].apply(treat_comment)

newDf

from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer()

label = newDf['emotion']
features = newDf['comment_text']
X = vectorizer.fit_transform(features)
Y = label
print(X.shape)



from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.25,random_state=42)
print(X_train.shape)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, Y_train)

model.score(X_train, Y_train)

from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

y_pred = model.predict(X_test)



accuracy_score(Y_test, y_pred)

import matplotlib.pyplot as plt


matrix = confusion_matrix(Y_test, y_pred)
f, ax = plt.subplots(figsize=(5,5))
sns.heatmap(matrix, annot=True, linewidths=0.01, cmap='Greens', linecolor="gray", fmt='.1f', ax=ax)

from sklearn.ensemble import GradientBoostingClassifier
 from sklearn.tree import DecisionTreeClassifier

from sklearn.tree import DecisionTreeClassifier

# Créer un modèle DecisionTreeClassifier
model2 = DecisionTreeClassifier()

# Adapter (entraîner) le modèle aux données d'entraînement
model2.fit(X_train, Y_train)

model2.score(X_train, Y_train)

y_pred = model2.predict(X_test)

accuracy_score(Y_test, y_pred)

matrix = confusion_matrix(Y_test, y_pred)
f, ax = plt.subplots(figsize=(5,5))
sns.heatmap(matrix, annot=True, linewidths=0.01, cmap='Greens', linecolor="gray", fmt='.1f', ax=ax)

import joblib as jb
jb.dump(model, "mon_modele_test.pkl")

jb.dump(vectorizer, "mon_vecteur_test.pkl")

import nltk
jb.__version__